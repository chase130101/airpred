{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data_split_utils import cross_validation_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### implementation of cross_validation\n",
    "def cross_validation(data, hyperparam_dict, num_folds, site_var_name = 'site'):\n",
    "    cross_validation_splits(data, num_folds, site_var_name='site')\n",
    "    \n",
    "    test_r2_list = []\n",
    "    mean_r2_list = []\n",
    "    for penalty in penalty_list:\n",
    "        \n",
    "        test_mse_list = []\n",
    "        for train_ind, test_ind in data_splitter.split(x, y):\n",
    "            \n",
    "            train_x = x.iloc[train_ind, :]\n",
    "            train_y = y.iloc[train_ind]\n",
    "\n",
    "            test_x = x.iloc[test_ind, :]\n",
    "            test_y = y.iloc[test_ind]\n",
    "            \n",
    "            median_imputer = sklearn.preprocessing.Imputer(strategy = 'median')\n",
    "            train_x_imp = median_imputer.fit_transform(train_x)\n",
    "            test_x_imp = median_imputer.transform(test_x)\n",
    "            \n",
    "            if interactions == True and poly_degree == 1:\n",
    "                feature_generator = sklearn.preprocessing.PolynomialFeatures(interaction_only = True, include_bias = False)\n",
    "                train_x_imp = feature_generator.fit_transform(train_x_imp)\n",
    "                test_x_imp = feature_generator.transform(test_x_imp)\n",
    "            elif interactions == True and poly_degree > 1:\n",
    "                feature_generator = sklearn.preprocessing.PolynomialFeatures(degree = poly_degree, include_bias = False)\n",
    "                train_x_imp = feature_generator.fit_transform(train_x_imp)\n",
    "                test_x_imp = feature_generator.transform(test_x_imp)\n",
    "\n",
    "            standardizer = sklearn.preprocessing.StandardScaler(with_mean = True, with_std = True)\n",
    "            train_x_imp_std = standardizer.fit_transform(train_x_imp)\n",
    "            test_x_imp_std = standardizer.transform(test_x_imp)\n",
    "            \n",
    "            lasso = sklearn.linear_model.Lasso(alpha=penalty, fit_intercept=True, random_state=1, max_iter = 10000)\n",
    "            lasso.fit(train_x_imp_std, train_y)\n",
    "            lasso_test_pred = lasso.predict(test_x_imp_std)\n",
    "            lasso_test_mse = sklearn.metrics.mean_squared_error(lasso_test_pred, test_y)\n",
    "            \n",
    "            test_mse_list.append(lasso_test_mse)\n",
    "            \n",
    "        mean_mse = np.mean(test_mse_list)\n",
    "        mean_mse_list.append(mean_mse)\n",
    "        \n",
    "        if penalty == penalty_list[0]:\n",
    "            best_mean_mse = np.mean(test_mse_list)\n",
    "            best_penalty = penalty\n",
    "            \n",
    "        elif mean_mse < best_mean_mse:\n",
    "            best_mean_mse = np.mean(test_mse_list)\n",
    "            best_penalty = penalty\n",
    "            \n",
    "    return best_mean_mse, best_penalty, mean_mse_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5.3",
   "language": "python",
   "name": "py35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
