{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.preprocessing\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in imputed data\n",
    "sensor_census_imp = pd.read_csv('../data/sensor_census_imputed_rf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "# get sites for val/test data\n",
    "val_test_sites = np.random.choice(np.unique(sensor_census_imp['site'].values), round(len(np.unique(sensor_census_imp['site'].values))/5), replace = False)\n",
    "\n",
    "# get sites for test data\n",
    "test_sites = np.random.choice(np.unique(val_test_sites), round(len(np.unique(val_test_sites))/2), replace = False)\n",
    "\n",
    "# train sites/rows and x/y split\n",
    "sensor_census_imp_train = sensor_census_imp[~sensor_census_imp['site'].isin(val_test_sites)]\n",
    "sensor_census_imp_train_x = sensor_census_imp_train.iloc[:, 2:]\n",
    "sensor_census_imp_train_y = sensor_census_imp_train.iloc[:, 1]\n",
    "\n",
    "# val sites/rows and x/y split\n",
    "sensor_census_imp_val = sensor_census_imp[(sensor_census_imp['site'].isin(val_test_sites)) & (~sensor_census_imp['site'].isin(test_sites))]\n",
    "sensor_census_imp_val_x = sensor_census_imp_val.iloc[:, 2:]\n",
    "sensor_census_imp_val_y = sensor_census_imp_val.iloc[:, 1]\n",
    "\n",
    "# test sites/rows and x/y split\n",
    "sensor_census_imp_test = sensor_census_imp[sensor_census_imp['site'].isin(test_sites)]\n",
    "sensor_census_imp_test_x = sensor_census_imp_test.iloc[:, 2:]\n",
    "sensor_census_imp_test_y = sensor_census_imp_test.iloc[:, 1]\n",
    "\n",
    "# standardize train, val, and test data\n",
    "standardizer = sklearn.preprocessing.StandardScaler(with_mean = True, with_std = True)\n",
    "sensor_census_imp_train_x_stand = standardizer.fit_transform(sensor_census_imp_train_x)\n",
    "sensor_census_imp_val_x_stand = standardizer.transform(sensor_census_imp_val_x)\n",
    "sensor_census_imp_test_x_stand = standardizer.transform(sensor_census_imp_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create torch tensor tuples for train, val, test\n",
    "train = TensorDataset(torch.from_numpy(sensor_census_imp_train_x_stand), torch.from_numpy(sensor_census_imp_train_y.values))\n",
    "val = TensorDataset(torch.from_numpy(sensor_census_imp_val_x_stand), torch.from_numpy(sensor_census_imp_val_y.values))\n",
    "test = TensorDataset(torch.from_numpy(sensor_census_imp_test_x_stand), torch.from_numpy(sensor_census_imp_test_y.values))\n",
    "\n",
    "# create batches\n",
    "batch_size = 100\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train, batch_size = batch_size, shuffle = True)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset = val, batch_size = batch_size, shuffle = False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model architecture\n",
    "ff_nn = torch.nn.Sequential()\n",
    "ff_nn.add_module(name = '1st linear', module = torch.nn.Linear(in_features = sensor_census_imp_train_x_stand.shape[1], out_features = 100, bias = True)) # linear layer\n",
    "ff_nn.add_module(name = 'norm', module = torch.nn.BatchNorm1d(num_features = 100)) # normalize before tanh\n",
    "ff_nn.add_module(name = 'tanh', module = torch.nn.Tanh()) # tanh function for hidden layer\n",
    "ff_nn.add_module(name = '2nd linear', module = torch.nn.Linear(in_features = 100, out_features = 1, bias = True)) # 2nd linear layer\n",
    "\n",
    "# mse loss\n",
    "loss_function = torch.nn.MSELoss()\n",
    "\n",
    "# adam optimizer\n",
    "adam = torch.optim.Adam(ff_nn.parameters(), lr=0.001, weight_decay=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for computing accuracy\n",
    "def compute_accuracy(data_loader, model):\n",
    "    model_pred = []\n",
    "    targets = []\n",
    "    for batch in data_loader:\n",
    "        model_output = model(Variable(batch[0]).float()).data.numpy() # model preds\n",
    "        model_pred += model_output.tolist() # add to list of preds\n",
    "        targets += batch[1].numpy().tolist() # true digit values\n",
    "        \n",
    "    return sklearn.metrics.r2_score(targets, model_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for lambda=0, learning rate=0.01, batch size=100, hidden units=100: 0.839866332868\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "\n",
    "for epoch in range(num_epochs):   \n",
    "    for batch in train_loader:\n",
    "        model_output = ff_nn(Variable(batch[0]).float()) # model predictions\n",
    "        targets = Variable(batch[1].float()) # true digit values\n",
    "\n",
    "        adam.zero_grad() # zero gradient\n",
    "        loss_batch = loss_function(model_output, targets) # compute loss\n",
    "        loss_batch.backward() # take the gradient wrt parameters\n",
    "        adam.step() # update parameters\n",
    "                    \n",
    "print('Test accuracy for lambda=' + str(0) + ', learning rate=' + str(0.01) + ', batch size='\\\n",
    "        + str(100) + ', hidden units=' + str(100) + ': ' + str(compute_accuracy(train_loader, ff_nn))) # compute validation acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5.3",
   "language": "python",
   "name": "py35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
